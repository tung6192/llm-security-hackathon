# questions.py
from utils import format_documents
from file_processing import search_documents, llm_search

from langchain_openai import OpenAIEmbeddings
from langchain.chains import RetrievalQA
from langchain.vectorstores import Chroma


class QuestionContext:
    def __init__(self, index, documents, llm_chain, model_name, repo_name, github_url, conversation_history, file_type_counts, filenames):
        self.index = index
        self.documents = documents
        self.llm_chain = llm_chain
        self.model_name = model_name
        self.repo_name = repo_name
        self.github_url = github_url
        self.conversation_history = conversation_history
        self.file_type_counts = file_type_counts
        self.filenames = filenames
        
        # self.doc_strings = self._from_document_to_string()
        # self.embedding_documents = self.embed_documents()
        
        self.vector_db = self.to_vector_db()
        self.qa_chain = RetrievalQA.from_chain_type(
                    llm=llm_chain,
                    chain_type="stuff",
                    retriever=self.vector_db.as_retriever(search_kwargs={"k": 3}),
                    verbose=True,
                )

    def to_vector_db(self):
        persist_directory = 'docs/chroma/'

        # Create the vector store
        vectordb = Chroma.from_documents(
            documents=self.documents,
            embedding=OpenAIEmbeddings(),
            persist_directory=persist_directory
        )
        return vectordb

    def _from_document_to_string(
        self
    ):
        return [doc.page_content for doc in self.documents]

    def embed_documents(self):
        embedding_model = OpenAIEmbeddings()
        self.embed_model = embedding_model
        embedding_docs = embedding_model.embed_documents(self.doc_strings)
        return embedding_docs
    
def ask_question(question, context: QuestionContext):
    relevant_docs = search_documents(question, context.index, context.documents, n_results=5)
    # relevant_docs = llm_search(context.embed_model,query=question,embedding_documents=context.embedding_documents,documents==context.documents, n_results=5,index=context.index)

    numbered_documents = format_documents(relevant_docs)
    question_context = f"This question is about the GitHub repository '{context.repo_name}' available at {context.github_url}. The most relevant documents are:\n\n{numbered_documents}"

    answer_with_sources = context.llm_chain.run(
        model=context.model_name,
        question=question,
        context=question_context,
        repo_name=context.repo_name,
        github_url=context.github_url,
        conversation_history=context.conversation_history,
        numbered_documents=numbered_documents,
        file_type_counts=context.file_type_counts,
        filenames=context.filenames
    )
    return answer_with_sources


def retrive_qa_question(question, context: QuestionContext):
    # question = "What are major topics for this class?"
    result = context.qa_chain.run(question)
    return result
